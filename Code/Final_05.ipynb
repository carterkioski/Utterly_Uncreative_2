{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy, AUC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# !pip install tensorflow-addons==0.9.1\n",
    "# import tensorflow_addons \n",
    "# from tensorflow_addons.metrics import F1Score, CohenKappacore, CohenKappa\n",
    "# from tensorflow_addons.metrics import F1Score, CohenKappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_type</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>DR</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>DR</td>\n",
       "      <td>Proliferate_DR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>DR</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>No_DR</td>\n",
       "      <td>No_DR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>No_DR</td>\n",
       "      <td>No_DR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis binary_type            type\n",
       "0  000c1434d8d7          2          DR        Moderate\n",
       "1  001639a390f0          4          DR  Proliferate_DR\n",
       "2  0024cdab0c1e          1          DR            Mild\n",
       "3  002c21358ce6          0       No_DR           No_DR\n",
       "4  005b95c28852          0       No_DR           No_DR"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an additional column, mapping to the type\n",
    "Image_info_df = pd.read_csv('../Data/Gaussian_Retina_Data/train.csv')\n",
    "\n",
    "diagnosis_dict_binary = {\n",
    "    0: 'No_DR',\n",
    "    1: 'DR',\n",
    "    2: 'DR',\n",
    "    3: 'DR',\n",
    "    4: 'DR'\n",
    "}\n",
    "\n",
    "diagnosis_dict = {\n",
    "    0: 'No_DR',\n",
    "    1: 'Mild',\n",
    "    2: 'Moderate',\n",
    "    3: 'Severe',\n",
    "    4: 'Proliferate_DR',\n",
    "}\n",
    "\n",
    "\n",
    "Image_info_df['binary_type'] =  Image_info_df['diagnosis'].map(diagnosis_dict_binary.get)\n",
    "Image_info_df['type'] = Image_info_df['diagnosis'].map(diagnosis_dict.get)\n",
    "Image_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x209e843bc50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image_info_df['type'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x209b5c7d748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image_info_df['binary_type'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_DR             1444\n",
      "Moderate           799\n",
      "Mild               278\n",
      "Proliferate_DR     251\n",
      "Severe             157\n",
      "Name: type, dtype: int64 \n",
      "\n",
      "No_DR             361\n",
      "Moderate          200\n",
      "Mild               92\n",
      "Proliferate_DR     44\n",
      "Severe             36\n",
      "Name: type, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split into stratified train, val, and test sets\n",
    "train, test = train_test_split(Image_info_df, test_size = 0.20)\n",
    "\n",
    "print(train['type'].value_counts(), '\\n')\n",
    "print(test['type'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working directories for train/val/test\n",
    "base_dir = ''\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "if os.path.exists(base_dir):\n",
    "    shutil.rmtree(base_dir)\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "os.makedirs(train_dir)\n",
    "\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "os.makedirs(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images to respective working directory\n",
    "src_dir = '../Data/Gaussian_Retina_Data/gaussian_filtered_images/gaussian_filtered_images/'\n",
    "for index, row in train.iterrows():\n",
    "    diagnosis = row['type']\n",
    "    binary_diagnosis = row['binary_type']\n",
    "    id_code = row['id_code'] + \".png\"\n",
    "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
    "    dstfile = os.path.join(train_dir, diagnosis)\n",
    "    os.makedirs(dstfile, exist_ok = True)\n",
    "    shutil.copy(srcfile, dstfile)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    diagnosis = row['type']\n",
    "    binary_diagnosis = row['binary_type']\n",
    "    id_code = row['id_code'] + \".png\"\n",
    "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
    "    dstfile = os.path.join(test_dir, diagnosis)\n",
    "    os.makedirs(dstfile, exist_ok = True)\n",
    "    shutil.copy(srcfile, dstfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2929 images belonging to 5 classes.\n",
      "Found 733 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setting up ImageDataGenerator for train/val/test \n",
    "\n",
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224), shuffle = True)\n",
    "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Layer CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 128)         295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 737,781\n",
      "Trainable params: 736,341\n",
      "Non-trainable params: 1,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "# LOOK AT NUMBER OF NODES\n",
    "# LOOK AT STACKING AND UNSTACKING as MULTIPLES OF 2\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), padding=\"same\", activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(1, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation = 'relu'),\n",
    "    layers.Dropout(0.15),\n",
    "    layers.Dense(5, activation = 'softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 [==============================] - 134s 1s/step - loss: 0.6896 - acc: 0.3520 - val_loss: 0.6915 - val_acc: 0.0477\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 131s 1s/step - loss: 0.5899 - acc: 0.4681 - val_loss: 0.6935 - val_acc: 0.0491\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 129s 1s/step - loss: 0.5453 - acc: 0.5183 - val_loss: 0.7016 - val_acc: 0.0450\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.5251 - acc: 0.5166 - val_loss: 0.7218 - val_acc: 0.0491\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.5102 - acc: 0.5449 - val_loss: 0.7223 - val_acc: 0.0723\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 127s 1s/step - loss: 0.4933 - acc: 0.5562 - val_loss: 0.6044 - val_acc: 0.3233\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.4837 - acc: 0.5647 - val_loss: 0.5204 - val_acc: 0.4679\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 124s 1s/step - loss: 0.4732 - acc: 0.5784 - val_loss: 0.4826 - val_acc: 0.5211\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.4638 - acc: 0.5818 - val_loss: 0.4689 - val_acc: 0.5484\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 0.4605 - acc: 0.5842 - val_loss: 0.4610 - val_acc: 0.5553\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 0.4510 - acc: 0.6033 - val_loss: 0.4547 - val_acc: 0.5689\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 0.4412 - acc: 0.6064 - val_loss: 0.4509 - val_acc: 0.5744\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 0.4365 - acc: 0.6122 - val_loss: 0.4478 - val_acc: 0.5730\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4305 - acc: 0.6221 - val_loss: 0.4452 - val_acc: 0.5675\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 0.4287 - acc: 0.6241 - val_loss: 0.4399 - val_acc: 0.5662\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 0.4256 - acc: 0.6111 - val_loss: 0.4367 - val_acc: 0.5798\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4214 - acc: 0.6408 - val_loss: 0.4341 - val_acc: 0.5798\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4100 - acc: 0.6507 - val_loss: 0.4299 - val_acc: 0.5812\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4136 - acc: 0.6446 - val_loss: 0.4282 - val_acc: 0.5880\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 115s 1s/step - loss: 0.4027 - acc: 0.6586 - val_loss: 0.4250 - val_acc: 0.5921\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 127s 1s/step - loss: 0.4044 - acc: 0.6576 - val_loss: 0.4202 - val_acc: 0.5948\n",
      "Epoch 22/100\n",
      "67/92 [====================>.........] - ETA: 31s - loss: 0.3976 - acc: 0.6707"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=100,\n",
    "                    validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.evaluate(test_batches, verbose=1)\n",
    "print(\"Accuracy: \", acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='center left')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='center right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Predict the label of the test_images\n",
    "pred = model.predict(test_batches)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_batches.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 10 predictions: {pred[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"Retinopathy_model_trained_100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "retinopathy_model = load_model(\"Retinopathy_model_trained_100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"voice_model_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = retinopathy_model.evaluate(\n",
    "    test_batches, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
