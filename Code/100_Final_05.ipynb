{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy, AUC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# !pip install tensorflow-addons==0.9.1\n",
    "# import tensorflow_addons \n",
    "# from tensorflow_addons.metrics import F1Score, CohenKappacore, CohenKappa\n",
    "# from tensorflow_addons.metrics import F1Score, CohenKappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_type</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>DR</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>DR</td>\n",
       "      <td>Proliferate_DR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>DR</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>No_DR</td>\n",
       "      <td>No_DR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>No_DR</td>\n",
       "      <td>No_DR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis binary_type            type\n",
       "0  000c1434d8d7          2          DR        Moderate\n",
       "1  001639a390f0          4          DR  Proliferate_DR\n",
       "2  0024cdab0c1e          1          DR            Mild\n",
       "3  002c21358ce6          0       No_DR           No_DR\n",
       "4  005b95c28852          0       No_DR           No_DR"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an additional column, mapping to the type\n",
    "Image_info_df = pd.read_csv('../Data/Gaussian_Retina_Data/train.csv')\n",
    "\n",
    "diagnosis_dict_binary = {\n",
    "    0: 'No_DR',\n",
    "    1: 'DR',\n",
    "    2: 'DR',\n",
    "    3: 'DR',\n",
    "    4: 'DR'\n",
    "}\n",
    "\n",
    "diagnosis_dict = {\n",
    "    0: 'No_DR',\n",
    "    1: 'Mild',\n",
    "    2: 'Moderate',\n",
    "    3: 'Severe',\n",
    "    4: 'Proliferate_DR',\n",
    "}\n",
    "\n",
    "\n",
    "Image_info_df['binary_type'] =  Image_info_df['diagnosis'].map(diagnosis_dict_binary.get)\n",
    "Image_info_df['type'] = Image_info_df['diagnosis'].map(diagnosis_dict.get)\n",
    "Image_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x209e843bc50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image_info_df['type'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x209b5c7d748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image_info_df['binary_type'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_DR             1444\n",
      "Moderate           799\n",
      "Mild               278\n",
      "Proliferate_DR     251\n",
      "Severe             157\n",
      "Name: type, dtype: int64 \n",
      "\n",
      "No_DR             361\n",
      "Moderate          200\n",
      "Mild               92\n",
      "Proliferate_DR     44\n",
      "Severe             36\n",
      "Name: type, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split into stratified train, val, and test sets\n",
    "train, test = train_test_split(Image_info_df, test_size = 0.20)\n",
    "\n",
    "print(train['type'].value_counts(), '\\n')\n",
    "print(test['type'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working directories for train/val/test\n",
    "base_dir = ''\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "if os.path.exists(base_dir):\n",
    "    shutil.rmtree(base_dir)\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "os.makedirs(train_dir)\n",
    "\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "os.makedirs(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images to respective working directory\n",
    "src_dir = '../Data/Gaussian_Retina_Data/gaussian_filtered_images/gaussian_filtered_images/'\n",
    "for index, row in train.iterrows():\n",
    "    diagnosis = row['type']\n",
    "    binary_diagnosis = row['binary_type']\n",
    "    id_code = row['id_code'] + \".png\"\n",
    "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
    "    dstfile = os.path.join(train_dir, diagnosis)\n",
    "    os.makedirs(dstfile, exist_ok = True)\n",
    "    shutil.copy(srcfile, dstfile)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    diagnosis = row['type']\n",
    "    binary_diagnosis = row['binary_type']\n",
    "    id_code = row['id_code'] + \".png\"\n",
    "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
    "    dstfile = os.path.join(test_dir, diagnosis)\n",
    "    os.makedirs(dstfile, exist_ok = True)\n",
    "    shutil.copy(srcfile, dstfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2929 images belonging to 5 classes.\n",
      "Found 733 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setting up ImageDataGenerator for train/val/test \n",
    "\n",
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224), shuffle = True)\n",
    "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Layer CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 128)         295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 737,781\n",
      "Trainable params: 736,341\n",
      "Non-trainable params: 1,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "# LOOK AT NUMBER OF NODES\n",
    "# LOOK AT STACKING AND UNSTACKING as MULTIPLES OF 2\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), padding=\"same\", activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(1, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation = 'relu'),\n",
    "    layers.Dropout(0.15),\n",
    "    layers.Dense(5, activation = 'softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 [==============================] - 134s 1s/step - loss: 0.6896 - acc: 0.3520 - val_loss: 0.6915 - val_acc: 0.0477\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 131s 1s/step - loss: 0.5899 - acc: 0.4681 - val_loss: 0.6935 - val_acc: 0.0491\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 129s 1s/step - loss: 0.5453 - acc: 0.5183 - val_loss: 0.7016 - val_acc: 0.0450\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.5251 - acc: 0.5166 - val_loss: 0.7218 - val_acc: 0.0491\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.5102 - acc: 0.5449 - val_loss: 0.7223 - val_acc: 0.0723\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 127s 1s/step - loss: 0.4933 - acc: 0.5562 - val_loss: 0.6044 - val_acc: 0.3233\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.4837 - acc: 0.5647 - val_loss: 0.5204 - val_acc: 0.4679\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 124s 1s/step - loss: 0.4732 - acc: 0.5784 - val_loss: 0.4826 - val_acc: 0.5211\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.4638 - acc: 0.5818 - val_loss: 0.4689 - val_acc: 0.5484\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 0.4605 - acc: 0.5842 - val_loss: 0.4610 - val_acc: 0.5553\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 0.4510 - acc: 0.6033 - val_loss: 0.4547 - val_acc: 0.5689\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 0.4412 - acc: 0.6064 - val_loss: 0.4509 - val_acc: 0.5744\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 0.4365 - acc: 0.6122 - val_loss: 0.4478 - val_acc: 0.5730\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4305 - acc: 0.6221 - val_loss: 0.4452 - val_acc: 0.5675\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 0.4287 - acc: 0.6241 - val_loss: 0.4399 - val_acc: 0.5662\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 0.4256 - acc: 0.6111 - val_loss: 0.4367 - val_acc: 0.5798\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4214 - acc: 0.6408 - val_loss: 0.4341 - val_acc: 0.5798\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4100 - acc: 0.6507 - val_loss: 0.4299 - val_acc: 0.5812\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.4136 - acc: 0.6446 - val_loss: 0.4282 - val_acc: 0.5880\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 115s 1s/step - loss: 0.4027 - acc: 0.6586 - val_loss: 0.4250 - val_acc: 0.5921\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 127s 1s/step - loss: 0.4044 - acc: 0.6576 - val_loss: 0.4202 - val_acc: 0.5948\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 122s 1s/step - loss: 0.4012 - acc: 0.6606 - val_loss: 0.4191 - val_acc: 0.6030\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 127s 1s/step - loss: 0.4009 - acc: 0.6623 - val_loss: 0.4160 - val_acc: 0.6085\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.3920 - acc: 0.6740 - val_loss: 0.4131 - val_acc: 0.6003\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 0.3881 - acc: 0.6726 - val_loss: 0.4103 - val_acc: 0.6030\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 168s 2s/step - loss: 0.3834 - acc: 0.6791 - val_loss: 0.4105 - val_acc: 0.6153\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.3790 - acc: 0.6927 - val_loss: 0.4087 - val_acc: 0.6030\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 163s 2s/step - loss: 0.3756 - acc: 0.6917 - val_loss: 0.4049 - val_acc: 0.5975\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 213s 2s/step - loss: 0.3755 - acc: 0.6852 - val_loss: 0.4020 - val_acc: 0.6071\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 203s 2s/step - loss: 0.3758 - acc: 0.6876 - val_loss: 0.4020 - val_acc: 0.6098\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.3732 - acc: 0.6961 - val_loss: 0.3990 - val_acc: 0.6153\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 188s 2s/step - loss: 0.3634 - acc: 0.7074 - val_loss: 0.3948 - val_acc: 0.6016\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 191s 2s/step - loss: 0.3614 - acc: 0.7112 - val_loss: 0.3979 - val_acc: 0.6030\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 194s 2s/step - loss: 0.3612 - acc: 0.7057 - val_loss: 0.3935 - val_acc: 0.6098\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 212s 2s/step - loss: 0.3545 - acc: 0.7170 - val_loss: 0.3908 - val_acc: 0.6153\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 215s 2s/step - loss: 0.3524 - acc: 0.7217 - val_loss: 0.3897 - val_acc: 0.6085\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 131s 1s/step - loss: 0.3496 - acc: 0.7197 - val_loss: 0.3887 - val_acc: 0.6207\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 126s 1s/step - loss: 0.3469 - acc: 0.7255 - val_loss: 0.3873 - val_acc: 0.6180\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 125s 1s/step - loss: 0.3497 - acc: 0.7187 - val_loss: 0.3855 - val_acc: 0.6180\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 149s 2s/step - loss: 0.3425 - acc: 0.7258 - val_loss: 0.3836 - val_acc: 0.6126\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 180s 2s/step - loss: 0.3435 - acc: 0.7303 - val_loss: 0.3870 - val_acc: 0.6098\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 169s 2s/step - loss: 0.3367 - acc: 0.7375 - val_loss: 0.3850 - val_acc: 0.6166\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 165s 2s/step - loss: 0.3359 - acc: 0.7395 - val_loss: 0.3821 - val_acc: 0.6126\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 174s 2s/step - loss: 0.3330 - acc: 0.7398 - val_loss: 0.3790 - val_acc: 0.6357\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 173s 2s/step - loss: 0.3356 - acc: 0.7354 - val_loss: 0.3806 - val_acc: 0.6180\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 201s 2s/step - loss: 0.3286 - acc: 0.7436 - val_loss: 0.3783 - val_acc: 0.6276\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 199s 2s/step - loss: 0.3315 - acc: 0.7409 - val_loss: 0.3797 - val_acc: 0.6139\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 182s 2s/step - loss: 0.3248 - acc: 0.7453 - val_loss: 0.3775 - val_acc: 0.6248\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.3206 - acc: 0.7504 - val_loss: 0.3750 - val_acc: 0.6289\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 174s 2s/step - loss: 0.3181 - acc: 0.7562 - val_loss: 0.3736 - val_acc: 0.6317\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 163s 2s/step - loss: 0.3161 - acc: 0.7532 - val_loss: 0.3720 - val_acc: 0.6344\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 171s 2s/step - loss: 0.3139 - acc: 0.7573 - val_loss: 0.3704 - val_acc: 0.6439\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 167s 2s/step - loss: 0.3110 - acc: 0.7675 - val_loss: 0.3707 - val_acc: 0.6385\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 169s 2s/step - loss: 0.3114 - acc: 0.7607 - val_loss: 0.3706 - val_acc: 0.6330\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 0.3106 - acc: 0.7583 - val_loss: 0.3698 - val_acc: 0.6398\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 166s 2s/step - loss: 0.3055 - acc: 0.7651 - val_loss: 0.3679 - val_acc: 0.6426\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.3061 - acc: 0.7685 - val_loss: 0.3666 - val_acc: 0.6521\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 136s 1s/step - loss: 0.2998 - acc: 0.7644 - val_loss: 0.3664 - val_acc: 0.6385\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 141s 2s/step - loss: 0.2998 - acc: 0.7675 - val_loss: 0.3648 - val_acc: 0.6412\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 133s 1s/step - loss: 0.2946 - acc: 0.7757 - val_loss: 0.3613 - val_acc: 0.6480\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 159s 2s/step - loss: 0.2906 - acc: 0.7791 - val_loss: 0.3605 - val_acc: 0.6453\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 189s 2s/step - loss: 0.2918 - acc: 0.7815 - val_loss: 0.3610 - val_acc: 0.6398\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 172s 2s/step - loss: 0.2883 - acc: 0.7815 - val_loss: 0.3614 - val_acc: 0.6385\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 194s 2s/step - loss: 0.2878 - acc: 0.7791 - val_loss: 0.3577 - val_acc: 0.6385\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 187s 2s/step - loss: 0.2856 - acc: 0.7781 - val_loss: 0.3573 - val_acc: 0.6521\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 193s 2s/step - loss: 0.2872 - acc: 0.7808 - val_loss: 0.3575 - val_acc: 0.6385\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 201s 2s/step - loss: 0.2805 - acc: 0.7911 - val_loss: 0.3571 - val_acc: 0.6412\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.2782 - acc: 0.7832 - val_loss: 0.3538 - val_acc: 0.6576\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.2848 - acc: 0.7716 - val_loss: 0.3566 - val_acc: 0.6467\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 182s 2s/step - loss: 0.2701 - acc: 0.7887 - val_loss: 0.3511 - val_acc: 0.6548\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 190s 2s/step - loss: 0.2721 - acc: 0.7969 - val_loss: 0.3525 - val_acc: 0.6426\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 190s 2s/step - loss: 0.2710 - acc: 0.7982 - val_loss: 0.3487 - val_acc: 0.6521\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 179s 2s/step - loss: 0.2641 - acc: 0.8105 - val_loss: 0.3502 - val_acc: 0.6357\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 211s 2s/step - loss: 0.2639 - acc: 0.8044 - val_loss: 0.3576 - val_acc: 0.6248\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 168s 2s/step - loss: 0.2598 - acc: 0.8071 - val_loss: 0.3477 - val_acc: 0.6439\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 163s 2s/step - loss: 0.2671 - acc: 0.7945 - val_loss: 0.3443 - val_acc: 0.6535\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 170s 2s/step - loss: 0.2604 - acc: 0.7986 - val_loss: 0.3520 - val_acc: 0.6303\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 145s 2s/step - loss: 0.2602 - acc: 0.7962 - val_loss: 0.3426 - val_acc: 0.6494\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 0.2568 - acc: 0.8044 - val_loss: 0.3450 - val_acc: 0.6439\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 156s 2s/step - loss: 0.2551 - acc: 0.8071 - val_loss: 0.3457 - val_acc: 0.6467\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 157s 2s/step - loss: 0.2484 - acc: 0.8160 - val_loss: 0.3404 - val_acc: 0.6480\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 164s 2s/step - loss: 0.2542 - acc: 0.8095 - val_loss: 0.3411 - val_acc: 0.6535\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 171s 2s/step - loss: 0.2469 - acc: 0.8078 - val_loss: 0.3392 - val_acc: 0.6548\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 168s 2s/step - loss: 0.2439 - acc: 0.8139 - val_loss: 0.3429 - val_acc: 0.6412\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 197s 2s/step - loss: 0.2446 - acc: 0.8061 - val_loss: 0.3375 - val_acc: 0.6726\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 184s 2s/step - loss: 0.2467 - acc: 0.8126 - val_loss: 0.3381 - val_acc: 0.6576\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 188s 2s/step - loss: 0.2395 - acc: 0.8197 - val_loss: 0.3372 - val_acc: 0.6535\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.2331 - acc: 0.8276 - val_loss: 0.3359 - val_acc: 0.6589\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 169s 2s/step - loss: 0.2372 - acc: 0.8156 - val_loss: 0.3348 - val_acc: 0.6589\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 164s 2s/step - loss: 0.2402 - acc: 0.8211 - val_loss: 0.3356 - val_acc: 0.6562\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.2339 - acc: 0.8139 - val_loss: 0.3334 - val_acc: 0.6603\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 191s 2s/step - loss: 0.2325 - acc: 0.8208 - val_loss: 0.3315 - val_acc: 0.6576\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.2267 - acc: 0.8276 - val_loss: 0.3299 - val_acc: 0.6603\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 145s 2s/step - loss: 0.2317 - acc: 0.8197 - val_loss: 0.3304 - val_acc: 0.6603\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 105s 1s/step - loss: 0.2270 - acc: 0.8255 - val_loss: 0.3265 - val_acc: 0.6808\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 0.2250 - acc: 0.8242 - val_loss: 0.3262 - val_acc: 0.6780\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.2250 - acc: 0.8228 - val_loss: 0.3263 - val_acc: 0.6671\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 114s 1s/step - loss: 0.2272 - acc: 0.8225 - val_loss: 0.3344 - val_acc: 0.6467\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 0.2233 - acc: 0.8269 - val_loss: 0.3252 - val_acc: 0.6753\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 0.2138 - acc: 0.8371 - val_loss: 0.3274 - val_acc: 0.6521\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=100,\n",
    "                    validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 352ms/step - loss: 0.3274 - acc: 0.6521\n",
      "Accuracy:  0.6521145701408386\n"
     ]
    }
   ],
   "source": [
    "acc = model.evaluate(test_batches, verbose=1)\n",
    "print(\"Accuracy: \", acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20981405828>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,3,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='lower right')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 predictions: ['Moderate', 'Proliferate_DR', 'Proliferate_DR', 'Proliferate_DR', 'Proliferate_DR', 'Proliferate_DR', 'Proliferate_DR', 'No_DR', 'Severe', 'Proliferate_DR']\n"
     ]
    }
   ],
   "source": [
    "#  Predict the label of the test_images\n",
    "pred = model.predict(test_batches)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_batches.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 10 predictions: {pred[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"Retinopathy_model_trained_100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "retinopathy_model = load_model(\"Retinopathy_model_trained_100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 8s - loss: 0.3274 - acc: 0.6521\n",
      "Normal Neural Network - Loss: 0.3273581564426422, Accuracy: 0.6521145701408386\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = retinopathy_model.evaluate(\n",
    "    test_batches, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x209e85b2128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Mild', 1: 'Moderate', 2: 'No_DR', 3: 'Proliferate_DR', 4: 'Severe'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.689613401889801,\n",
       "  0.589885413646698,\n",
       "  0.5453456044197083,\n",
       "  0.5250523090362549,\n",
       "  0.5101675987243652,\n",
       "  0.4933442771434784,\n",
       "  0.4836743474006653,\n",
       "  0.47317519783973694,\n",
       "  0.4638115465641022,\n",
       "  0.46053552627563477,\n",
       "  0.4510166347026825,\n",
       "  0.4412117898464203,\n",
       "  0.4365213215351105,\n",
       "  0.43048736453056335,\n",
       "  0.4286656081676483,\n",
       "  0.4256402254104614,\n",
       "  0.42136913537979126,\n",
       "  0.40997421741485596,\n",
       "  0.4135645925998688,\n",
       "  0.4027225971221924,\n",
       "  0.4044218957424164,\n",
       "  0.40116414427757263,\n",
       "  0.40085268020629883,\n",
       "  0.3919580280780792,\n",
       "  0.38805699348449707,\n",
       "  0.38344961404800415,\n",
       "  0.37901443243026733,\n",
       "  0.3756190538406372,\n",
       "  0.3754619359970093,\n",
       "  0.37580859661102295,\n",
       "  0.37319445610046387,\n",
       "  0.3634006083011627,\n",
       "  0.36138829588890076,\n",
       "  0.361207515001297,\n",
       "  0.3545309901237488,\n",
       "  0.3524259626865387,\n",
       "  0.3496493399143219,\n",
       "  0.34685736894607544,\n",
       "  0.3497190773487091,\n",
       "  0.34249091148376465,\n",
       "  0.3434838652610779,\n",
       "  0.3366793990135193,\n",
       "  0.3359401822090149,\n",
       "  0.3329612612724304,\n",
       "  0.33564525842666626,\n",
       "  0.3285652697086334,\n",
       "  0.33146029710769653,\n",
       "  0.3248281478881836,\n",
       "  0.32064715027809143,\n",
       "  0.31811925768852234,\n",
       "  0.3161258399486542,\n",
       "  0.31389671564102173,\n",
       "  0.3110085129737854,\n",
       "  0.31137651205062866,\n",
       "  0.31061574816703796,\n",
       "  0.30553552508354187,\n",
       "  0.3060930073261261,\n",
       "  0.299760103225708,\n",
       "  0.2998198866844177,\n",
       "  0.2946474850177765,\n",
       "  0.29055750370025635,\n",
       "  0.2917640507221222,\n",
       "  0.28825467824935913,\n",
       "  0.2878343164920807,\n",
       "  0.28561797738075256,\n",
       "  0.28718462586402893,\n",
       "  0.2805333733558655,\n",
       "  0.2782294452190399,\n",
       "  0.28476768732070923,\n",
       "  0.2700873613357544,\n",
       "  0.2720566391944885,\n",
       "  0.27102893590927124,\n",
       "  0.26412665843963623,\n",
       "  0.2638971209526062,\n",
       "  0.2598172128200531,\n",
       "  0.2670779526233673,\n",
       "  0.26040154695510864,\n",
       "  0.2601667046546936,\n",
       "  0.25678497552871704,\n",
       "  0.2550981938838959,\n",
       "  0.24844840168952942,\n",
       "  0.25424322485923767,\n",
       "  0.24685154855251312,\n",
       "  0.24389219284057617,\n",
       "  0.24463917315006256,\n",
       "  0.2466919720172882,\n",
       "  0.23954322934150696,\n",
       "  0.23311562836170197,\n",
       "  0.23715610802173615,\n",
       "  0.24023786187171936,\n",
       "  0.23393914103507996,\n",
       "  0.23253491520881653,\n",
       "  0.2267143726348877,\n",
       "  0.23170824348926544,\n",
       "  0.22696453332901,\n",
       "  0.22502097487449646,\n",
       "  0.22496157884597778,\n",
       "  0.22717861831188202,\n",
       "  0.22333617508411407,\n",
       "  0.21380090713500977],\n",
       " 'acc': [0.3519972562789917,\n",
       "  0.4680778384208679,\n",
       "  0.5182656049728394,\n",
       "  0.5165585279464722,\n",
       "  0.5448958873748779,\n",
       "  0.5561625361442566,\n",
       "  0.5646978616714478,\n",
       "  0.5783543586730957,\n",
       "  0.5817685127258301,\n",
       "  0.5841584205627441,\n",
       "  0.6032775640487671,\n",
       "  0.606350302696228,\n",
       "  0.6121543049812317,\n",
       "  0.6220552921295166,\n",
       "  0.6241037845611572,\n",
       "  0.6111300587654114,\n",
       "  0.6408330202102661,\n",
       "  0.6507340669631958,\n",
       "  0.6445885896682739,\n",
       "  0.6585865616798401,\n",
       "  0.6575623154640198,\n",
       "  0.6606350541114807,\n",
       "  0.6623420715332031,\n",
       "  0.6739501357078552,\n",
       "  0.6725844740867615,\n",
       "  0.6790713667869568,\n",
       "  0.6927278637886047,\n",
       "  0.6917036771774292,\n",
       "  0.6852167844772339,\n",
       "  0.687606692314148,\n",
       "  0.6961420178413391,\n",
       "  0.7074086666107178,\n",
       "  0.7111642360687256,\n",
       "  0.7057015895843506,\n",
       "  0.7169682383537292,\n",
       "  0.7217480540275574,\n",
       "  0.7196995615959167,\n",
       "  0.7255035638809204,\n",
       "  0.7186753153800964,\n",
       "  0.7258449792861938,\n",
       "  0.7302833795547485,\n",
       "  0.737453043460846,\n",
       "  0.7395015358924866,\n",
       "  0.73984295129776,\n",
       "  0.7354045510292053,\n",
       "  0.7435985207557678,\n",
       "  0.7408671975135803,\n",
       "  0.7453055381774902,\n",
       "  0.7504267692565918,\n",
       "  0.7562307715415955,\n",
       "  0.7531580924987793,\n",
       "  0.7572550177574158,\n",
       "  0.7674974203109741,\n",
       "  0.7606691718101501,\n",
       "  0.7582792639732361,\n",
       "  0.7651075720787048,\n",
       "  0.7685216665267944,\n",
       "  0.764424741268158,\n",
       "  0.7674974203109741,\n",
       "  0.7756913900375366,\n",
       "  0.7791054844856262,\n",
       "  0.7814953923225403,\n",
       "  0.7814953923225403,\n",
       "  0.7791054844856262,\n",
       "  0.7780812382698059,\n",
       "  0.7808125615119934,\n",
       "  0.7910549640655518,\n",
       "  0.7832024693489075,\n",
       "  0.7715944051742554,\n",
       "  0.7886650562286377,\n",
       "  0.7968590259552002,\n",
       "  0.7982246279716492,\n",
       "  0.8105155229568481,\n",
       "  0.804370105266571,\n",
       "  0.8071014285087585,\n",
       "  0.7944691181182861,\n",
       "  0.7985660433769226,\n",
       "  0.7961761951446533,\n",
       "  0.804370105266571,\n",
       "  0.8071014285087585,\n",
       "  0.8159781694412231,\n",
       "  0.8094912767410278,\n",
       "  0.8077841997146606,\n",
       "  0.8139296770095825,\n",
       "  0.8060771822929382,\n",
       "  0.8125640153884888,\n",
       "  0.8197336792945862,\n",
       "  0.8275862336158752,\n",
       "  0.8156367540359497,\n",
       "  0.8210993409156799,\n",
       "  0.8139296770095825,\n",
       "  0.8207579255104065,\n",
       "  0.8275862336158752,\n",
       "  0.8197336792945862,\n",
       "  0.8255377411842346,\n",
       "  0.8241720795631409,\n",
       "  0.8228064179420471,\n",
       "  0.8224650025367737,\n",
       "  0.8269034028053284,\n",
       "  0.8371458053588867],\n",
       " 'val_loss': [0.6914742588996887,\n",
       "  0.6934543251991272,\n",
       "  0.7015647292137146,\n",
       "  0.7218452095985413,\n",
       "  0.7222874760627747,\n",
       "  0.6044455170631409,\n",
       "  0.5203772783279419,\n",
       "  0.48258891701698303,\n",
       "  0.4689437747001648,\n",
       "  0.46096599102020264,\n",
       "  0.4546540081501007,\n",
       "  0.45091843605041504,\n",
       "  0.4477573335170746,\n",
       "  0.4451802372932434,\n",
       "  0.4398878514766693,\n",
       "  0.43665337562561035,\n",
       "  0.43412816524505615,\n",
       "  0.42985573410987854,\n",
       "  0.4282166063785553,\n",
       "  0.4250413477420807,\n",
       "  0.42021384835243225,\n",
       "  0.41907232999801636,\n",
       "  0.415975958108902,\n",
       "  0.4131218194961548,\n",
       "  0.410306841135025,\n",
       "  0.4104558527469635,\n",
       "  0.4086562693119049,\n",
       "  0.4048829674720764,\n",
       "  0.4020169973373413,\n",
       "  0.40197786688804626,\n",
       "  0.39898180961608887,\n",
       "  0.3948328495025635,\n",
       "  0.3979407250881195,\n",
       "  0.3934938609600067,\n",
       "  0.39078694581985474,\n",
       "  0.3896816074848175,\n",
       "  0.38874074816703796,\n",
       "  0.38729724287986755,\n",
       "  0.3855229914188385,\n",
       "  0.38362598419189453,\n",
       "  0.3870279788970947,\n",
       "  0.3850053548812866,\n",
       "  0.382133424282074,\n",
       "  0.3790303170681,\n",
       "  0.3806130588054657,\n",
       "  0.3783019483089447,\n",
       "  0.3796786367893219,\n",
       "  0.37745192646980286,\n",
       "  0.37498992681503296,\n",
       "  0.37358149886131287,\n",
       "  0.3720034956932068,\n",
       "  0.3704051673412323,\n",
       "  0.37071099877357483,\n",
       "  0.3705625534057617,\n",
       "  0.3698464035987854,\n",
       "  0.3679419755935669,\n",
       "  0.36659276485443115,\n",
       "  0.36635661125183105,\n",
       "  0.36478760838508606,\n",
       "  0.3612818419933319,\n",
       "  0.36046814918518066,\n",
       "  0.36098501086235046,\n",
       "  0.3613860011100769,\n",
       "  0.3576538860797882,\n",
       "  0.35726654529571533,\n",
       "  0.357464462518692,\n",
       "  0.357148140668869,\n",
       "  0.35375556349754333,\n",
       "  0.3565777540206909,\n",
       "  0.3510538637638092,\n",
       "  0.35254955291748047,\n",
       "  0.348672479391098,\n",
       "  0.35022255778312683,\n",
       "  0.35760045051574707,\n",
       "  0.34766367077827454,\n",
       "  0.344300240278244,\n",
       "  0.3519544303417206,\n",
       "  0.3426494598388672,\n",
       "  0.3450291156768799,\n",
       "  0.3457292914390564,\n",
       "  0.3403972387313843,\n",
       "  0.34111452102661133,\n",
       "  0.3391638398170471,\n",
       "  0.3428851068019867,\n",
       "  0.33745038509368896,\n",
       "  0.33808159828186035,\n",
       "  0.33715948462486267,\n",
       "  0.33587920665740967,\n",
       "  0.3347519636154175,\n",
       "  0.33557891845703125,\n",
       "  0.3333683907985687,\n",
       "  0.33152931928634644,\n",
       "  0.3298739194869995,\n",
       "  0.3303515911102295,\n",
       "  0.32651451230049133,\n",
       "  0.3261943459510803,\n",
       "  0.32631218433380127,\n",
       "  0.3343547582626343,\n",
       "  0.3251643478870392,\n",
       "  0.3273581564426422],\n",
       " 'val_acc': [0.047748975455760956,\n",
       "  0.049113232642412186,\n",
       "  0.045020464807748795,\n",
       "  0.049113232642412186,\n",
       "  0.0723055899143219,\n",
       "  0.32332879304885864,\n",
       "  0.46793997287750244,\n",
       "  0.5211459994316101,\n",
       "  0.5484310984611511,\n",
       "  0.5552523732185364,\n",
       "  0.5688949227333069,\n",
       "  0.574351966381073,\n",
       "  0.5729877352714539,\n",
       "  0.5675306916236877,\n",
       "  0.5661664605140686,\n",
       "  0.5798090100288391,\n",
       "  0.5798090100288391,\n",
       "  0.5811732411384583,\n",
       "  0.5879945158958435,\n",
       "  0.5920873284339905,\n",
       "  0.5948158502578735,\n",
       "  0.6030013561248779,\n",
       "  0.608458399772644,\n",
       "  0.6002728343009949,\n",
       "  0.6030013561248779,\n",
       "  0.6152796745300293,\n",
       "  0.6030013561248779,\n",
       "  0.5975443124771118,\n",
       "  0.6070941090583801,\n",
       "  0.6098226308822632,\n",
       "  0.6152796745300293,\n",
       "  0.6016371250152588,\n",
       "  0.6030013561248779,\n",
       "  0.6098226308822632,\n",
       "  0.6152796745300293,\n",
       "  0.608458399772644,\n",
       "  0.6207367181777954,\n",
       "  0.6180081963539124,\n",
       "  0.6180081963539124,\n",
       "  0.6125511527061462,\n",
       "  0.6098226308822632,\n",
       "  0.6166439056396484,\n",
       "  0.6125511527061462,\n",
       "  0.6357434988021851,\n",
       "  0.6180081963539124,\n",
       "  0.6275579929351807,\n",
       "  0.6139154434204102,\n",
       "  0.6248294711112976,\n",
       "  0.6289222240447998,\n",
       "  0.6316507458686829,\n",
       "  0.6343792676925659,\n",
       "  0.6439290642738342,\n",
       "  0.6384720206260681,\n",
       "  0.6330150365829468,\n",
       "  0.639836311340332,\n",
       "  0.6425647735595703,\n",
       "  0.6521145701408386,\n",
       "  0.6384720206260681,\n",
       "  0.6412005424499512,\n",
       "  0.6480218172073364,\n",
       "  0.6452932953834534,\n",
       "  0.639836311340332,\n",
       "  0.6384720206260681,\n",
       "  0.6384720206260681,\n",
       "  0.6521145701408386,\n",
       "  0.6384720206260681,\n",
       "  0.6412005424499512,\n",
       "  0.6575716137886047,\n",
       "  0.6466575860977173,\n",
       "  0.6548430919647217,\n",
       "  0.6425647735595703,\n",
       "  0.6521145701408386,\n",
       "  0.6357434988021851,\n",
       "  0.6248294711112976,\n",
       "  0.6439290642738342,\n",
       "  0.6534788608551025,\n",
       "  0.6302865147590637,\n",
       "  0.6493861079216003,\n",
       "  0.6439290642738342,\n",
       "  0.6466575860977173,\n",
       "  0.6480218172073364,\n",
       "  0.6534788608551025,\n",
       "  0.6548430919647217,\n",
       "  0.6412005424499512,\n",
       "  0.6725784540176392,\n",
       "  0.6575716137886047,\n",
       "  0.6534788608551025,\n",
       "  0.6589359045028687,\n",
       "  0.6589359045028687,\n",
       "  0.6562073826789856,\n",
       "  0.6603001356124878,\n",
       "  0.6575716137886047,\n",
       "  0.6603001356124878,\n",
       "  0.6603001356124878,\n",
       "  0.6807639598846436,\n",
       "  0.6780354976654053,\n",
       "  0.667121410369873,\n",
       "  0.6466575860977173,\n",
       "  0.6753069758415222,\n",
       "  0.6521145701408386]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history.history)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(history.history, orient=\"index\")\n",
    "df.to_csv(\"history_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.689613</td>\n",
       "      <td>0.589885</td>\n",
       "      <td>0.545346</td>\n",
       "      <td>0.525052</td>\n",
       "      <td>0.510168</td>\n",
       "      <td>0.493344</td>\n",
       "      <td>0.483674</td>\n",
       "      <td>0.473175</td>\n",
       "      <td>0.463812</td>\n",
       "      <td>0.460536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233939</td>\n",
       "      <td>0.232535</td>\n",
       "      <td>0.226714</td>\n",
       "      <td>0.231708</td>\n",
       "      <td>0.226965</td>\n",
       "      <td>0.225021</td>\n",
       "      <td>0.224962</td>\n",
       "      <td>0.227179</td>\n",
       "      <td>0.223336</td>\n",
       "      <td>0.213801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.351997</td>\n",
       "      <td>0.468078</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>0.516559</td>\n",
       "      <td>0.544896</td>\n",
       "      <td>0.556163</td>\n",
       "      <td>0.564698</td>\n",
       "      <td>0.578354</td>\n",
       "      <td>0.581769</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813930</td>\n",
       "      <td>0.820758</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.819734</td>\n",
       "      <td>0.825538</td>\n",
       "      <td>0.824172</td>\n",
       "      <td>0.822806</td>\n",
       "      <td>0.822465</td>\n",
       "      <td>0.826903</td>\n",
       "      <td>0.837146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.691474</td>\n",
       "      <td>0.693454</td>\n",
       "      <td>0.701565</td>\n",
       "      <td>0.721845</td>\n",
       "      <td>0.722287</td>\n",
       "      <td>0.604446</td>\n",
       "      <td>0.520377</td>\n",
       "      <td>0.482589</td>\n",
       "      <td>0.468944</td>\n",
       "      <td>0.460966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333368</td>\n",
       "      <td>0.331529</td>\n",
       "      <td>0.329874</td>\n",
       "      <td>0.330352</td>\n",
       "      <td>0.326515</td>\n",
       "      <td>0.326194</td>\n",
       "      <td>0.326312</td>\n",
       "      <td>0.334355</td>\n",
       "      <td>0.325164</td>\n",
       "      <td>0.327358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_acc</th>\n",
       "      <td>0.047749</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>0.045020</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>0.072306</td>\n",
       "      <td>0.323329</td>\n",
       "      <td>0.467940</td>\n",
       "      <td>0.521146</td>\n",
       "      <td>0.548431</td>\n",
       "      <td>0.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>0.657572</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>0.680764</td>\n",
       "      <td>0.678035</td>\n",
       "      <td>0.667121</td>\n",
       "      <td>0.646658</td>\n",
       "      <td>0.675307</td>\n",
       "      <td>0.652115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "loss      0.689613  0.589885  0.545346  0.525052  0.510168  0.493344   \n",
       "acc       0.351997  0.468078  0.518266  0.516559  0.544896  0.556163   \n",
       "val_loss  0.691474  0.693454  0.701565  0.721845  0.722287  0.604446   \n",
       "val_acc   0.047749  0.049113  0.045020  0.049113  0.072306  0.323329   \n",
       "\n",
       "                 6         7         8         9  ...        90        91  \\\n",
       "loss      0.483674  0.473175  0.463812  0.460536  ...  0.233939  0.232535   \n",
       "acc       0.564698  0.578354  0.581769  0.584158  ...  0.813930  0.820758   \n",
       "val_loss  0.520377  0.482589  0.468944  0.460966  ...  0.333368  0.331529   \n",
       "val_acc   0.467940  0.521146  0.548431  0.555252  ...  0.660300  0.657572   \n",
       "\n",
       "                92        93        94        95        96        97  \\\n",
       "loss      0.226714  0.231708  0.226965  0.225021  0.224962  0.227179   \n",
       "acc       0.827586  0.819734  0.825538  0.824172  0.822806  0.822465   \n",
       "val_loss  0.329874  0.330352  0.326515  0.326194  0.326312  0.334355   \n",
       "val_acc   0.660300  0.660300  0.680764  0.678035  0.667121  0.646658   \n",
       "\n",
       "                98        99  \n",
       "loss      0.223336  0.213801  \n",
       "acc       0.826903  0.837146  \n",
       "val_loss  0.325164  0.327358  \n",
       "val_acc   0.675307  0.652115  \n",
       "\n",
       "[4 rows x 100 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_history=pd.read_csv(\"history_data.csv\", index_col=0)\n",
    "reload_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_history = reload_history.to_dict(\"split\")\n",
    "\n",
    "new_history = dict(zip(new_history[\"index\"], new_history[\"data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.689613401889801,\n",
       "  0.589885413646698,\n",
       "  0.5453456044197083,\n",
       "  0.5250523090362549,\n",
       "  0.5101675987243652,\n",
       "  0.4933442771434784,\n",
       "  0.4836743474006653,\n",
       "  0.473175197839737,\n",
       "  0.4638115465641022,\n",
       "  0.4605355262756348,\n",
       "  0.4510166347026825,\n",
       "  0.4412117898464203,\n",
       "  0.4365213215351105,\n",
       "  0.43048736453056335,\n",
       "  0.4286656081676483,\n",
       "  0.4256402254104614,\n",
       "  0.4213691353797913,\n",
       "  0.409974217414856,\n",
       "  0.4135645925998688,\n",
       "  0.4027225971221924,\n",
       "  0.4044218957424164,\n",
       "  0.40116414427757263,\n",
       "  0.4008526802062988,\n",
       "  0.3919580280780792,\n",
       "  0.38805699348449707,\n",
       "  0.38344961404800415,\n",
       "  0.3790144324302673,\n",
       "  0.3756190538406372,\n",
       "  0.3754619359970093,\n",
       "  0.37580859661102295,\n",
       "  0.3731944561004639,\n",
       "  0.3634006083011627,\n",
       "  0.3613882958889008,\n",
       "  0.36120751500129705,\n",
       "  0.3545309901237488,\n",
       "  0.3524259626865387,\n",
       "  0.3496493399143219,\n",
       "  0.34685736894607544,\n",
       "  0.3497190773487091,\n",
       "  0.34249091148376465,\n",
       "  0.3434838652610779,\n",
       "  0.3366793990135193,\n",
       "  0.3359401822090149,\n",
       "  0.3329612612724304,\n",
       "  0.33564525842666626,\n",
       "  0.3285652697086334,\n",
       "  0.3314602971076965,\n",
       "  0.3248281478881836,\n",
       "  0.32064715027809143,\n",
       "  0.31811925768852234,\n",
       "  0.3161258399486542,\n",
       "  0.3138967156410217,\n",
       "  0.3110085129737854,\n",
       "  0.31137651205062866,\n",
       "  0.310615748167038,\n",
       "  0.3055355250835419,\n",
       "  0.3060930073261261,\n",
       "  0.299760103225708,\n",
       "  0.2998198866844177,\n",
       "  0.2946474850177765,\n",
       "  0.29055750370025635,\n",
       "  0.2917640507221222,\n",
       "  0.28825467824935913,\n",
       "  0.2878343164920807,\n",
       "  0.28561797738075256,\n",
       "  0.2871846258640289,\n",
       "  0.2805333733558655,\n",
       "  0.2782294452190399,\n",
       "  0.28476768732070923,\n",
       "  0.2700873613357544,\n",
       "  0.2720566391944885,\n",
       "  0.27102893590927124,\n",
       "  0.26412665843963623,\n",
       "  0.2638971209526062,\n",
       "  0.2598172128200531,\n",
       "  0.2670779526233673,\n",
       "  0.26040154695510864,\n",
       "  0.2601667046546936,\n",
       "  0.25678497552871704,\n",
       "  0.2550981938838959,\n",
       "  0.24844840168952945,\n",
       "  0.2542432248592377,\n",
       "  0.2468515485525131,\n",
       "  0.24389219284057614,\n",
       "  0.24463917315006256,\n",
       "  0.2466919720172882,\n",
       "  0.23954322934150696,\n",
       "  0.233115628361702,\n",
       "  0.2371561080217361,\n",
       "  0.24023786187171936,\n",
       "  0.23393914103508,\n",
       "  0.2325349152088165,\n",
       "  0.2267143726348877,\n",
       "  0.23170824348926544,\n",
       "  0.22696453332901,\n",
       "  0.2250209748744965,\n",
       "  0.22496157884597776,\n",
       "  0.227178618311882,\n",
       "  0.22333617508411407,\n",
       "  0.21380090713500974],\n",
       " 'acc': [0.3519972562789917,\n",
       "  0.4680778384208679,\n",
       "  0.5182656049728394,\n",
       "  0.5165585279464722,\n",
       "  0.5448958873748779,\n",
       "  0.5561625361442566,\n",
       "  0.5646978616714478,\n",
       "  0.5783543586730957,\n",
       "  0.5817685127258301,\n",
       "  0.5841584205627441,\n",
       "  0.6032775640487671,\n",
       "  0.606350302696228,\n",
       "  0.6121543049812317,\n",
       "  0.6220552921295166,\n",
       "  0.6241037845611572,\n",
       "  0.6111300587654114,\n",
       "  0.6408330202102661,\n",
       "  0.6507340669631958,\n",
       "  0.6445885896682739,\n",
       "  0.6585865616798401,\n",
       "  0.6575623154640198,\n",
       "  0.6606350541114807,\n",
       "  0.6623420715332031,\n",
       "  0.6739501357078552,\n",
       "  0.6725844740867615,\n",
       "  0.6790713667869568,\n",
       "  0.6927278637886047,\n",
       "  0.6917036771774292,\n",
       "  0.6852167844772339,\n",
       "  0.687606692314148,\n",
       "  0.6961420178413391,\n",
       "  0.7074086666107178,\n",
       "  0.7111642360687256,\n",
       "  0.7057015895843506,\n",
       "  0.7169682383537292,\n",
       "  0.7217480540275574,\n",
       "  0.7196995615959167,\n",
       "  0.7255035638809204,\n",
       "  0.7186753153800964,\n",
       "  0.7258449792861938,\n",
       "  0.7302833795547485,\n",
       "  0.737453043460846,\n",
       "  0.7395015358924866,\n",
       "  0.73984295129776,\n",
       "  0.7354045510292053,\n",
       "  0.7435985207557678,\n",
       "  0.7408671975135803,\n",
       "  0.7453055381774902,\n",
       "  0.7504267692565918,\n",
       "  0.7562307715415955,\n",
       "  0.7531580924987793,\n",
       "  0.7572550177574158,\n",
       "  0.7674974203109741,\n",
       "  0.7606691718101501,\n",
       "  0.7582792639732361,\n",
       "  0.7651075720787048,\n",
       "  0.7685216665267944,\n",
       "  0.764424741268158,\n",
       "  0.7674974203109741,\n",
       "  0.7756913900375366,\n",
       "  0.7791054844856262,\n",
       "  0.7814953923225403,\n",
       "  0.7814953923225403,\n",
       "  0.7791054844856262,\n",
       "  0.7780812382698059,\n",
       "  0.7808125615119934,\n",
       "  0.7910549640655518,\n",
       "  0.7832024693489075,\n",
       "  0.7715944051742554,\n",
       "  0.7886650562286377,\n",
       "  0.7968590259552002,\n",
       "  0.7982246279716492,\n",
       "  0.8105155229568481,\n",
       "  0.8043701052665709,\n",
       "  0.8071014285087585,\n",
       "  0.7944691181182861,\n",
       "  0.7985660433769226,\n",
       "  0.7961761951446533,\n",
       "  0.8043701052665709,\n",
       "  0.8071014285087585,\n",
       "  0.8159781694412231,\n",
       "  0.8094912767410278,\n",
       "  0.8077841997146606,\n",
       "  0.8139296770095825,\n",
       "  0.8060771822929382,\n",
       "  0.8125640153884888,\n",
       "  0.8197336792945862,\n",
       "  0.8275862336158752,\n",
       "  0.8156367540359497,\n",
       "  0.8210993409156799,\n",
       "  0.8139296770095825,\n",
       "  0.8207579255104065,\n",
       "  0.8275862336158752,\n",
       "  0.8197336792945862,\n",
       "  0.8255377411842346,\n",
       "  0.8241720795631409,\n",
       "  0.8228064179420471,\n",
       "  0.8224650025367737,\n",
       "  0.8269034028053284,\n",
       "  0.8371458053588867],\n",
       " 'val_loss': [0.6914742588996887,\n",
       "  0.6934543251991272,\n",
       "  0.7015647292137146,\n",
       "  0.7218452095985413,\n",
       "  0.7222874760627747,\n",
       "  0.6044455170631409,\n",
       "  0.5203772783279419,\n",
       "  0.482588917016983,\n",
       "  0.4689437747001648,\n",
       "  0.4609659910202026,\n",
       "  0.4546540081501007,\n",
       "  0.450918436050415,\n",
       "  0.4477573335170746,\n",
       "  0.4451802372932434,\n",
       "  0.4398878514766693,\n",
       "  0.4366533756256104,\n",
       "  0.43412816524505615,\n",
       "  0.42985573410987854,\n",
       "  0.4282166063785553,\n",
       "  0.4250413477420807,\n",
       "  0.42021384835243225,\n",
       "  0.4190723299980164,\n",
       "  0.41597595810890203,\n",
       "  0.4131218194961548,\n",
       "  0.410306841135025,\n",
       "  0.4104558527469635,\n",
       "  0.4086562693119049,\n",
       "  0.4048829674720764,\n",
       "  0.4020169973373413,\n",
       "  0.4019778668880463,\n",
       "  0.3989818096160889,\n",
       "  0.3948328495025635,\n",
       "  0.3979407250881195,\n",
       "  0.3934938609600067,\n",
       "  0.3907869458198547,\n",
       "  0.3896816074848175,\n",
       "  0.388740748167038,\n",
       "  0.3872972428798676,\n",
       "  0.3855229914188385,\n",
       "  0.3836259841918945,\n",
       "  0.3870279788970947,\n",
       "  0.3850053548812866,\n",
       "  0.382133424282074,\n",
       "  0.3790303170681,\n",
       "  0.3806130588054657,\n",
       "  0.3783019483089447,\n",
       "  0.3796786367893219,\n",
       "  0.3774519264698029,\n",
       "  0.37498992681503296,\n",
       "  0.3735814988613129,\n",
       "  0.3720034956932068,\n",
       "  0.3704051673412323,\n",
       "  0.3707109987735748,\n",
       "  0.3705625534057617,\n",
       "  0.3698464035987854,\n",
       "  0.3679419755935669,\n",
       "  0.3665927648544312,\n",
       "  0.3663566112518311,\n",
       "  0.3647876083850861,\n",
       "  0.3612818419933319,\n",
       "  0.3604681491851807,\n",
       "  0.3609850108623505,\n",
       "  0.3613860011100769,\n",
       "  0.3576538860797882,\n",
       "  0.3572665452957153,\n",
       "  0.357464462518692,\n",
       "  0.35714814066886896,\n",
       "  0.3537555634975433,\n",
       "  0.3565777540206909,\n",
       "  0.3510538637638092,\n",
       "  0.3525495529174805,\n",
       "  0.348672479391098,\n",
       "  0.35022255778312683,\n",
       "  0.3576004505157471,\n",
       "  0.3476636707782745,\n",
       "  0.34430024027824396,\n",
       "  0.3519544303417206,\n",
       "  0.3426494598388672,\n",
       "  0.3450291156768799,\n",
       "  0.3457292914390564,\n",
       "  0.3403972387313843,\n",
       "  0.3411145210266113,\n",
       "  0.3391638398170471,\n",
       "  0.3428851068019867,\n",
       "  0.33745038509368896,\n",
       "  0.33808159828186035,\n",
       "  0.3371594846248627,\n",
       "  0.3358792066574097,\n",
       "  0.3347519636154175,\n",
       "  0.33557891845703125,\n",
       "  0.3333683907985687,\n",
       "  0.33152931928634644,\n",
       "  0.3298739194869995,\n",
       "  0.3303515911102295,\n",
       "  0.3265145123004913,\n",
       "  0.3261943459510803,\n",
       "  0.3263121843338013,\n",
       "  0.3343547582626343,\n",
       "  0.3251643478870392,\n",
       "  0.3273581564426422],\n",
       " 'val_acc': [0.04774897545576096,\n",
       "  0.04911323264241218,\n",
       "  0.0450204648077488,\n",
       "  0.04911323264241218,\n",
       "  0.0723055899143219,\n",
       "  0.32332879304885864,\n",
       "  0.4679399728775024,\n",
       "  0.5211459994316101,\n",
       "  0.5484310984611511,\n",
       "  0.5552523732185364,\n",
       "  0.5688949227333069,\n",
       "  0.574351966381073,\n",
       "  0.5729877352714539,\n",
       "  0.5675306916236877,\n",
       "  0.5661664605140686,\n",
       "  0.5798090100288391,\n",
       "  0.5798090100288391,\n",
       "  0.5811732411384583,\n",
       "  0.5879945158958435,\n",
       "  0.5920873284339905,\n",
       "  0.5948158502578735,\n",
       "  0.6030013561248779,\n",
       "  0.608458399772644,\n",
       "  0.6002728343009949,\n",
       "  0.6030013561248779,\n",
       "  0.6152796745300293,\n",
       "  0.6030013561248779,\n",
       "  0.5975443124771118,\n",
       "  0.6070941090583801,\n",
       "  0.6098226308822632,\n",
       "  0.6152796745300293,\n",
       "  0.6016371250152588,\n",
       "  0.6030013561248779,\n",
       "  0.6098226308822632,\n",
       "  0.6152796745300293,\n",
       "  0.608458399772644,\n",
       "  0.6207367181777954,\n",
       "  0.6180081963539124,\n",
       "  0.6180081963539124,\n",
       "  0.6125511527061462,\n",
       "  0.6098226308822632,\n",
       "  0.6166439056396484,\n",
       "  0.6125511527061462,\n",
       "  0.6357434988021851,\n",
       "  0.6180081963539124,\n",
       "  0.6275579929351807,\n",
       "  0.6139154434204102,\n",
       "  0.6248294711112976,\n",
       "  0.6289222240447998,\n",
       "  0.6316507458686829,\n",
       "  0.6343792676925659,\n",
       "  0.6439290642738342,\n",
       "  0.6384720206260681,\n",
       "  0.6330150365829468,\n",
       "  0.639836311340332,\n",
       "  0.6425647735595703,\n",
       "  0.6521145701408386,\n",
       "  0.6384720206260681,\n",
       "  0.6412005424499512,\n",
       "  0.6480218172073364,\n",
       "  0.6452932953834534,\n",
       "  0.639836311340332,\n",
       "  0.6384720206260681,\n",
       "  0.6384720206260681,\n",
       "  0.6521145701408386,\n",
       "  0.6384720206260681,\n",
       "  0.6412005424499512,\n",
       "  0.6575716137886047,\n",
       "  0.6466575860977173,\n",
       "  0.6548430919647217,\n",
       "  0.6425647735595703,\n",
       "  0.6521145701408386,\n",
       "  0.6357434988021851,\n",
       "  0.6248294711112976,\n",
       "  0.6439290642738342,\n",
       "  0.6534788608551025,\n",
       "  0.6302865147590637,\n",
       "  0.6493861079216003,\n",
       "  0.6439290642738342,\n",
       "  0.6466575860977173,\n",
       "  0.6480218172073364,\n",
       "  0.6534788608551025,\n",
       "  0.6548430919647217,\n",
       "  0.6412005424499512,\n",
       "  0.6725784540176392,\n",
       "  0.6575716137886047,\n",
       "  0.6534788608551025,\n",
       "  0.6589359045028687,\n",
       "  0.6589359045028687,\n",
       "  0.6562073826789856,\n",
       "  0.6603001356124878,\n",
       "  0.6575716137886047,\n",
       "  0.6603001356124878,\n",
       "  0.6603001356124878,\n",
       "  0.6807639598846436,\n",
       "  0.6780354976654053,\n",
       "  0.6671214103698729,\n",
       "  0.6466575860977173,\n",
       "  0.6753069758415222,\n",
       "  0.6521145701408386]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Mild',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Mild',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Mild',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Severe',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Mild',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'No_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'No_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Severe',\n",
       " 'Moderate',\n",
       " 'Moderate',\n",
       " 'Severe',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR',\n",
       " 'Proliferate_DR']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"pred.csv\", 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "     wr.writerow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2929 images belonging to 5 classes.\n",
      "Found 733 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "\n",
    "train_x_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224), shuffle = True)\n",
    "test_x_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
